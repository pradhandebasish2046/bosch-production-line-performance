{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7139ce66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .time    { background: #40CC40; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tbody td { text-align: left; }\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .sp {  opacity: 0.25;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import datatable as dt\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from datatable.models import Ftrl\n",
    "import pickle\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import make_scorer, matthews_corrcoef\n",
    "from datetime import datetime\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import lightgbm as lgb\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ad5b8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('final_df_train_3.0.csv')\n",
    "df.fillna(0,inplace=True)\n",
    "df.drop(['Unnamed: 0','kurtosis','max_num_value','skewness','skewness_imp_st','mean_num_value','sum_num_value_imp_st','sum_num_value','mean_num_value_imp_st'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74e8b75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('final_df_test_3.0.csv')\n",
    "df_test.fillna(0,inplace=True)\n",
    "df_test.drop(['Unnamed: 0','kurtosis','max_num_value','skewness','skewness_imp_st','mean_num_value','sum_num_value_imp_st','sum_num_value','mean_num_value_imp_st'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "631461bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = df['Response']\n",
    "X= df.drop(['Id','Response'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "551fc798",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,Y,test_size=0.2, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b8bb864",
   "metadata": {},
   "source": [
    "# Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31e8d237",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Debasish Pradhan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(random_state=0).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "000f80b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d15745f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db493f12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.00027405881426615394"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matthews_corrcoef(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "899bbb0d",
   "metadata": {},
   "source": [
    "# Custom Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05708b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1, X_train2, y_train1, y_train2 = train_test_split(X_train,y_train,test_size=0.5, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab4e2c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_xgb=xgb.XGBClassifier(booster='gbtree', colsample_bylevel=1,\n",
    "       colsample_bytree=0.3, gamma=3.2, learning_rate=0.5,\n",
    "       max_delta_step=0, max_depth=3, min_child_weight=12, missing=1,\n",
    "       n_estimators=65, n_jobs=1,random_state=0,\n",
    "       objective='binary:logistic', reg_alpha=1.6,\n",
    "       reg_lambda=0.2, scale_pos_weight=1, seed=None, silent=True,\n",
    "       subsample=1,use_label_encoder=False)\n",
    "\n",
    "model_dt=DecisionTreeClassifier(splitter='best',min_weight_fraction_leaf=0.1,min_samples_leaf=1,max_leaf_nodes=30,max_features='sqrt',max_depth=9)\n",
    "\n",
    "model_lgb = lgb.LGBMClassifier(colsample_bytree= 0.43455527965836527,\n",
    " min_child_samples= 198,\n",
    " min_child_weight= 10.0,\n",
    " num_leaves= 12,\n",
    " reg_alpha= 0.1,\n",
    " reg_lambda= 0.1,\n",
    " subsample= 0.36181919064442924)\n",
    "\n",
    "model_adb = AdaBoostClassifier(n_estimators=7,learning_rate=0.97,algorithm='SAMME.R')\n",
    "\n",
    "model_gbdt = GradientBoostingClassifier(n_estimators=16,min_samples_split=0.5,min_samples_leaf=0.2,max_features=7,max_depth=21.0,learning_rate=1)\n",
    "\n",
    "model_rf=RandomForestClassifier(n_estimators=1800,min_samples_split=10,min_samples_leaf=2,max_features='sqrt',max_depth=10,bootstrap=True)\n",
    "\n",
    "#model_svm = SVC(kernel = 'rbf', gamma = 0.0001, C = 10, probability = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ef62783b",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_to_train = [model_xgb,model_dt,model_lgb,model_adb,model_gbdt,model_rf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1d5b353f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import copy\n",
    "df1 = copy(X_train1)\n",
    "df1['Response'] = y_train1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8c29679a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_ensemble(model_list,dateframe,x2,y2,xtest,ytest,k):\n",
    "    n = len(dateframe)//k\n",
    "    sample_df = dateframe.sample(n)\n",
    "    \n",
    "    x1 = sample_df.drop('Response',axis=1)\n",
    "    y1 = sample_df['Response']\n",
    "    \n",
    "    predict_df = pd.DataFrame()\n",
    "    predict_test_df = pd.DataFrame()\n",
    "    predict_df_kaggle = pd.DataFrame()\n",
    "    \n",
    "    predict_prob_df = pd.DataFrame()\n",
    "    predict_test_prob_df = pd.DataFrame()\n",
    "    predict_prob_df_kaggle = pd.DataFrame()\n",
    "    \n",
    "    for i in tqdm(range(k)):\n",
    "        model = model_list[i]\n",
    "        model.fit(x1,y1)\n",
    "        \n",
    "        y_pred = model.predict(x2)\n",
    "        y_pred_prob = model.predict_proba(x2)\n",
    "        \n",
    "        predict_df[str(i+1)+'_prediction'] = y_pred\n",
    "        predict_prob_df[str(i+1)+'_prediction_prob 0'] = y_pred_prob[:,0]\n",
    "        predict_prob_df[str(i+1)+'_prediction_prob 1'] = y_pred_prob[:,1]\n",
    "        \n",
    "        \n",
    "        y_pred_test = model.predict(xtest)\n",
    "        y_pred_prob_test = model.predict_proba(xtest)\n",
    "        \n",
    "        predict_test_df[str(i+1)+'_prediction'] = y_pred_test\n",
    "        predict_test_prob_df[str(i+1)+'_prediction_prob 0'] = y_pred_prob_test[:,0]\n",
    "        predict_test_prob_df[str(i+1)+'_prediction_prob 1'] = y_pred_prob_test[:,1]\n",
    "        \n",
    "        '''y_pred_kaggle = model.predict(df_test.drop('Id',axis=1))\n",
    "        y_pred_prob_kaggle = model.predict_proba(df_test.drop('Id',axis=1))\n",
    "        \n",
    "        predict_df_kaggle[str(i+1)+'_prediction'] = y_pred_kaggle\n",
    "        predict_prob_df_kaggle[str(i+1)+'_prediction_prob 0'] = y_pred_prob_kaggle[:,0]\n",
    "        predict_prob_df_kaggle[str(i+1)+'_prediction_prob 1'] = y_pred_prob_kaggle[:,1]'''\n",
    "        \n",
    "        print(f\"After {i+1}th model the final shape of train data is {predict_df.shape} and {predict_prob_df.shape}\")\n",
    "        print(f\"After {i+1}th model the final shape of test data is {predict_test_df.shape} and {predict_test_prob_df.shape}\")\n",
    "        \n",
    "    return predict_df, predict_prob_df, predict_test_df, predict_test_prob_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b7b6e9b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:31:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[13:31:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|██████████████                                                                      | 1/6 [00:23<01:56, 23.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After 1th model the final shape of train data is (473499, 1) and (473499, 2)\n",
      "After 1th model the final shape of test data is (236750, 1) and (236750, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|████████████████████████████                                                        | 2/6 [00:27<00:48, 12.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After 2th model the final shape of train data is (473499, 2) and (473499, 4)\n",
      "After 2th model the final shape of test data is (236750, 2) and (236750, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|██████████████████████████████████████████                                          | 3/6 [00:49<00:49, 16.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After 3th model the final shape of train data is (473499, 3) and (473499, 6)\n",
      "After 3th model the final shape of test data is (236750, 3) and (236750, 6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|████████████████████████████████████████████████████████                            | 4/6 [01:04<00:31, 16.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After 4th model the final shape of train data is (473499, 4) and (473499, 8)\n",
      "After 4th model the final shape of test data is (236750, 4) and (236750, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 83%|██████████████████████████████████████████████████████████████████████              | 5/6 [01:09<00:12, 12.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After 5th model the final shape of train data is (473499, 5) and (473499, 10)\n",
      "After 5th model the final shape of test data is (236750, 5) and (236750, 10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 6/6 [10:27<00:00, 104.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After 6th model the final shape of train data is (473499, 6) and (473499, 12)\n",
      "After 6th model the final shape of test data is (236750, 6) and (236750, 12)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "df_train, df_train_prob_df, df_test, df_test_prob_df = custom_ensemble(models_to_train,df1,X_train2,y_train2,X_test,y_test,len(models_to_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b9afd215",
   "metadata": {},
   "outputs": [],
   "source": [
    "metamodel = xgb.XGBClassifier(booster='gbtree', colsample_bylevel=1,\n",
    "       colsample_bytree=0.3, gamma=3.2, learning_rate=0.5,\n",
    "       max_delta_step=0, max_depth=3, min_child_weight=12, missing=1,\n",
    "       n_estimators=65, n_jobs=1,random_state=0,\n",
    "       objective='binary:logistic', reg_alpha=1.6,\n",
    "       reg_lambda=0.2, scale_pos_weight=1, seed=None, silent=True,\n",
    "       subsample=1,use_label_encoder=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "16816593",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:46:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[13:46:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.3, gamma=3.2, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.5, max_delta_step=0, max_depth=3,\n",
       "              min_child_weight=12, missing=1, monotone_constraints='()',\n",
       "              n_estimators=65, n_jobs=1, num_parallel_tree=1, random_state=0,\n",
       "              reg_alpha=1.6, reg_lambda=0.2, scale_pos_weight=1, seed=0,\n",
       "              silent=True, subsample=1, tree_method='exact',\n",
       "              use_label_encoder=False, validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metamodel.fit(df_train,y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f56c32eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(236750, 282)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5989f48b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.27024204458214207"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = metamodel.predict(df_test)\n",
    "matthews_corrcoef(y_pred,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c7ffdbc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:48:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[13:48:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.3, gamma=3.2, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.5, max_delta_step=0, max_depth=3,\n",
       "              min_child_weight=12, missing=1, monotone_constraints='()',\n",
       "              n_estimators=65, n_jobs=1, num_parallel_tree=1, random_state=0,\n",
       "              reg_alpha=1.6, reg_lambda=0.2, scale_pos_weight=1, seed=0,\n",
       "              silent=True, subsample=1, tree_method='exact',\n",
       "              use_label_encoder=False, validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metamodel.fit(df_train_prob_df,y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cda9d836",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2882907990820504"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = metamodel.predict(df_test_prob_df)\n",
    "matthews_corrcoef(y_pred,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f85a70e",
   "metadata": {},
   "source": [
    "# Voting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c599271a",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = []\n",
    "estimator.append(('xgb', model_xgb))\n",
    "estimator.append(('dt', model_dt))\n",
    "estimator.append(('lgm', model_lgb))\n",
    "estimator.append(('adb',model_adb))\n",
    "estimator.append(('gbdt',model_gbdt))\n",
    "estimator.append(('rf',model_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "685911e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:00:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:00:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "vot_soft = VotingClassifier(estimators = estimator, voting ='soft')\n",
    "vot_soft.fit(X_train, y_train)\n",
    "y_soft = vot_soft.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "15060830",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1334819530614064"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matthews_corrcoef(y_test,y_soft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a6382519",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = vot_soft.predict(df_test.drop('Id',axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a9f12adf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "155"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c=0\n",
    "for i in y_pred_test:\n",
    "    if i == 1:\n",
    "        c+=1\n",
    "c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bfaf96d",
   "metadata": {},
   "source": [
    "## Summarizing the result using Python Pretty Table "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e117ecbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------+------------------------+-----------------------+----------------------+\n",
      "|     Model Name    | Train Result | Test/Validation Result | Kaggle Private Result | Kaggle Public Result |\n",
      "+-------------------+--------------+------------------------+-----------------------+----------------------+\n",
      "|      XGBoost      |    0.325     |         0.303          |         0.307         |        0.298         |\n",
      "|   Random Forest   |    0.237     |         0.198          |          ----         |         ----         |\n",
      "|     Light GBM     |    0.321     |         0.303          |         0.303         |        0.305         |\n",
      "|     Ada Boost     |    0.221     |         0.206          |         0.214         |        0.218         |\n",
      "|  Custom Ensemble  |     ----     |         0.288          |          ----         |         ----         |\n",
      "| Voting Classifier |     ----     |         0.133          |          ----         |         ----         |\n",
      "+-------------------+--------------+------------------------+-----------------------+----------------------+\n"
     ]
    }
   ],
   "source": [
    "from prettytable import PrettyTable\n",
    "\n",
    "myTable = PrettyTable([\"Model Name\", \"Train Result\", \"Test/Validation Result\", \"Kaggle Private Result\",\"Kaggle Public Result\"])\n",
    "\n",
    "myTable.add_row([\"XGBoost\", \"0.325\", \"0.303\", \"0.307\",\"0.298\"])\n",
    "myTable.add_row([\"Random Forest\", \"0.237\", \"0.198\", \"----\",\"----\"])\n",
    "myTable.add_row([\"Light GBM\", \"0.321\", \"0.303\", \"0.303\",\"0.305\"])\n",
    "myTable.add_row([\"Ada Boost\", \"0.221\", \"0.206\", \"0.214\",\"0.218\"])\n",
    "myTable.add_row([\"Custom Ensemble\", \"----\", \"0.288\", \"----\",\"----\"])\n",
    "myTable.add_row([\"Voting Classifier\", \"----\", \"0.133\", \"----\",\"----\"])\n",
    "\n",
    "print(myTable)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "374b1791",
   "metadata": {},
   "source": [
    "# At the end I conclude that XGBoost with some hyperparameter tuning giving me the best Result "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
